#OPTIMIZED MAIN SCRIPT for eDNA sequence analysis pipeline #
# Paige Smallman, 2025

#you may need to use cutadapt before running this to trim adapters

################################################################
# (1) SET UP & PARAMETERS
################################################################

# User-defined variables; change these for specific project
project_id <- "ROHR05"              # Project identifier (e.g. ROHR05)
primer <- "12S"                     # Primers used (e.g. 12S, COI, 16S)
tax_db <- "MIDORI2_UNIQ_NUC_GB264_srRNA_DADA2.fasta"  # Taxonomy database

# Core directories (modify if folder structure changes)
input_root <- here("inputs")
output_root <- here("outputs", project_id)
figures_root <- here("figures", project_id)

# Create directories if they don't exist
dir.create(output_root, showWarnings = FALSE)
dir.create(figures_root, showWarnings = FALSE)

# Load packages
required_packages <- c("dada2", "here", "ggplot2", "phyloseq", "decontam", 
                       "metagMisc", "devtools", "lulu", "DECIPHER", "rBLAST",
                       "tidyverse", "phangorn")
invisible(lapply(required_packages, require, character.only = TRUE))

# Input paths
metadata_path <- here(input_root, "metadata", "metadata.csv")
trimmed_path <- here(input_root, "trimmed", project_id, primer)

# Output paths
dada2_output <- here(output_root, paste0(project_id, "_dada2.rds"))
track_table_path <- here(output_root, paste0(project_id, "_read_changes.txt"))
nochim_output <- here(output_root, paste0(project_id, "_nochim.rds"))
tax_table_path <- here(output_root, paste0(project_id, "_taxtable.rds"))
phyloseq_path <- here(output_root, paste0(project_id, "_phyloseq.rds"))

# Taxonomy database path
tax_db_path <- here("tax", tax_db)

# Load metadata
metadata <- read.csv(metadata_path, header=TRUE, sep=",", row.names = NULL)

################################################################
# (2) PIPELINE EXECUTION
################################################################

# (A) Initial Quality Assessment
source("scripts/Quality_Assessment.R")  # This script is a function to generate quality plots for sequence reads

# Execute quality plotting
quality_data <- generate_quality_plots(
  pathinput = trimmed_path,
  pathfigures = figures_root
)

# view quality plots

# (B) User-Defined Parameters (Modify After Viewing Plots)

# TRUNCATION PARAMETER GUIDELINES
# 1. truncLen: Set to positions where median quality > Q30
#    - Check 00_quality_forward.png and 00_quality_reverse.png
#    - Example: Forward drops at 220bp, Reverse at 200bp â†’ c(220,200)
# 2. maxEE: Maximum expected errors (typically 2-3 for each read)
# 3. truncQ: Truncate when quality scores drop below this value (usually 2)

trunc_params <- list(
  truncLen = c(220, 200),  # Set based on quality plots
  maxEE = c(2, 2),         # Maximum expected errors
  truncQ = 2               # Truncate at first quality score < 2
)

# (C) Infer ASVs
source("scripts/ASV_Processing.R")    # This script filters + trims reads, infers Amplicon Sequence Variants (ASVs)

processing_results <- run_dada2_processing(
  fnFs = quality_data$fnFs,
   fnRs = quality_data$fnRs,
   pathinput = trimmed_path,
   pathoutput = dada2_output,
   pathoutput_tracktable = track_table_path,
   pathoutput_nochim_rds = nochim_output,
   pathfigures = figures_root,
   trunc_params = trunc_params,
   ncores = 8
)

# (D) Taxonomy Assignment
source("scripts/Assign_Taxonomy_DADA2.R")   # This script assigns taxonomy using Dada2 Midori database to create an otu table

tax_results <- assign_taxonomy(
  seqtab_nochim_rds = nochim_output,
  tax_db_path = tax_db_path,
  output_dir = output_root,
  project_id = project_id,
  ncores = 8,
  seed = 119
)

# (E) Phyloseq Object Creation
source("scripts/Phyloseq.R")          # This script creates a phyloseq object

phy_results <- create_phyloseq(
  otu_table_rds = nochim_output,
  tax_table_rds = tax_table_path,
  metadata_path = metadata_path,
  output_dir = output_root,
  project_id = project_id,
  sample_id_col = 2,
  fix_mismatches = TRUE
)

################################################################
# (3) MARKER SPECIFIC STEPS
################################################################

## 12S -------------------------------------------------------------------

# Remove contaminants with Decontam

# Assign taxonomy with BLAST

# Curation LCA with Galaxy tool

## CO1 ---------------------------------------------------------------------

# Remove contaminants with Decontam

# Cluster ASVs with Decipher

# Create match list with Vsearch

# Curate OTUs with lulu

#Assign taxonomy with BLAST

#Curation LCA with Galaxy tool
