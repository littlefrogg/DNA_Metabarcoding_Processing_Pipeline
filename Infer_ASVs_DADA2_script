# Step C script for eDNA sequence analysis pipeline 
# DADA2 ASV_Processing
# This script filters + trims reads, infers Amplicon Sequence Variants (ASVs)
# called from Main Script with user-defined parameters

run_dada2_processing <- function(
    fnFs, 
    fnRs,
    pathinput,
    pathoutput,
    pathoutput_tracktable,
    pathoutput_nochim_rds,
    pathfigures,
    trunc_params,
    ncores = TRUE) {
  
# Load required packages (this is redundant in case you didn't just run other parts of the main script)
  suppressPackageStartupMessages({
    require(dada2)
    require(here)
    require(ggplot2)
  })
  
# Create output directories
dir.create(pathfigures, showWarnings = FALSE, recursive = TRUE)
filtered_path <- file.path(pathinput, "filtered")
dir.create(filtered_path, showWarnings = FALSE)
  
# PARAMETER VALIDATION
  
  validate_parameters <- function(trunc_params) {
    if(length(trunc_params$truncLen) != 2) {
      stop("truncLen requires 2 values (forward/reverse truncation)")
    }
    if(any(trunc_params$truncLen < 0)) {
      stop("truncLen must be positive values")
    }
    if(length(trunc_params$maxEE) != 2) {
      stop("maxEE requires 2 values (forward/reverse max expected errors)")
    }
    return(TRUE)
  }
  
  tryCatch(
    validate_parameters(trunc_params),
    error = function(e) {
      stop("Parameter validation failed: ", e$message)
    }
  )
  
# FILTERING AND TRIMMING
  
message("\nStarting processing with parameters:")
message(paste(capture.output(print(trunc_params)), collapse = "\n"))
    
# Set filtered file paths
filtFs <- file.path(filtered_path, paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(filtered_path, paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- names(filtRs) <- sample.names
  
# Perform filtering
  filter_stats <- filterAndTrim(
    fwd = fnFs, filt = filtFs,
    rev = fnRs, filt.rev = filtRs,
    truncLen = trunc_params$truncLen,
    maxN = 0,
    maxEE = trunc_params$maxEE,
    truncQ = trunc_params$truncQ,
    rm.phix = TRUE,
    compress = TRUE,
    multithread = ncores
  )
 
# POST-FILTERING PROCESSING

# Remove samples with zero reads after filtering
keep <- file.exists(filtFs) & file.exists(filtRs)
filtFs <- filtFs[keep]
filtRs <- filtRs[keep]

  if(length(filtFs) == 0) {
    stop("No samples remaining after filtering. Check input files and parameters.")
  }
  
# ERROR MODELING
  
message("\nLearning error models...")
# Learn error rates with multithreading and randomization
errF <- learnErrors(filtFs, multithread = ncores, randomize = TRUE)
errR <- learnErrors(filtRs, multithread = ncores, randomize = TRUE)

# Plot error profiles (nominalQ = TRUE is standard, FALSE for troubleshooting)
plotErrors(errF, nominalQ = TRUE)
plotErrors(errR, nominalQ = TRUE)
  
# Dereplicate reads and assign names
sam.names <- tools::file_path_sans_ext(basename(filtFs))
derepFs <- derepFastq(filtFs, verbose = TRUE)
names(derepFs) <- sam.names
derepRs <- derepFastq(filtRs, verbose = TRUE)
names(derepRs) <- sam.names
  
# Sample inference
dadaFs <- dada(derepFs, err = errF, multithread = TRUE)
dadaRs <- dada(derepRs, err = errR, multithread = TRUE)
  
# Merge paired ends
  mergers <- mergePairs(
    dadaFs, derepFs,
    dadaRs, derepRs,
    verbose = TRUE
  )
  
# Construct sequence table
seqtab <- makeSequenceTable(mergers)
message("\nInitial ASV table dimensions: ", paste(dim(seqtab), collapse = " x "))
  
  if (COI_seqtab) {
  message("Filtering ASVs to keep only those with length 310â€“316 bp")
  seqtab <- seqtab[, nchar(colnames(seqtab)) %in% 310:316]
} else {
  message("Keeping all ASVs regardless of length")
}

# CHIMERA REMOVAL

  seqtab_nochim <- removeBimeraDenovo(
    seqtab,
    method = "consensus",
    multithread = 10,
    verbose = TRUE
  )
message("Post-chimera removal dimensions: ", paste(dim(seqtab_nochim), collapse = " x "))
  
# OUTPUT GENERATION
 
# Save sequence tables
saveRDS(seqtab, pathoutput)
saveRDS(seqtab_nochim, pathoutput_nochim_rds)
write.csv(seqtab.nochim, pathoutput_nochim_csv)
  
# Create tracking table
getN <- function(x) sum(getUniques(x))
  track <- cbind(
    filter_stats[keep,],
    sapply(dadaFs, getN),
    sapply(dadaRs, getN),
    sapply(mergers, getN),
    rowSums(seqtab_nochim)
  )
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
  
write.table(track, pathoutput_tracktable, sep = "\t", quote = FALSE, col.names = NA)
  
message("\nASV processing complete!")
message("Output files saved to:")
message("- ASV Table: ", pathoutput)
message("- Chimera-free Table: ", pathoutput_nochim_rds)
message("- Read Tracking: ", pathoutput_tracktable)
  
  return(list(
    seqtab = seqtab,
    seqtab_nochim = seqtab_nochim,
    track = track
  ))
}


# EXECUTION EXAMPLE

# Note: This section is called from the main script with parameters
# Example execution:
# processing_results <- run_dada2_processing(
#   fnFs = quality_data$fnFs,
#   fnRs = quality_data$fnRs,
#   pathinput = trimmed_path,
#   pathoutput = dada2_output,
#   pathoutput_tracktable = track_table_path,
#   pathoutput_nochim_rds = nochim_output,
#   pathoutput_nochim_csv = nochim_csv,
#   pathfigures = figures_root,
#   trunc_params = trunc_params,
#   ncores = 8
# )
