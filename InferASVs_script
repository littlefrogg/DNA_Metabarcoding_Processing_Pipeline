# Filter Reads, Trim Reads, Infer Amplicon Sequence Variants (ASVs)

##Creating filepath to data 
# pathinput <- here("inputs/trimmed_ROHR05_12S")
head(list.files(pathinput)) #to check if the path works

##File preparation
#extracting Forward (fnFs) and Reverse (fnRs) reads from files
#take these out??? #fnFs <-file.path(pathinput, fnFs)
##fnRs <-file.path(pathinput, fnRs)
fnFs <- sort(list.files(pathinput, pattern = "_R1_001.trimmed.fastq", full.names = TRUE))
fnRs <- sort(list.files(pathinput, pattern = "_R2_001.trimmed.fastq", full.names = TRUE))
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)

# if filtered files exist, find subdirectory for filtered files
filtFs <- file.path(pathinput, "filtered")
filtRs <- file.path(pathinput, "filtered")

#if filtered files do not exist, plot, filter and trim: 
#plotting quality profiles
 qprofile_fwd <- print(plotQualityProfile(fnFs, aggregate = TRUE) 
                      + ggtitle("Forward"))
 qprofile_rev <- print(plotQualityProfile(fnRs, aggregate = TRUE) 
                     + ggtitle("Reverse"))
# these may take a few minutes to run
# decide where to cut off ends (around where quality score dips below 30)
# change truncLen below accordingly

filtFs <- file.path(pathinput, "filtered", paste0(sample.names, "_F_filt.fastq"))
filtRs <- file.path(pathinput, "filtered", paste0(sample.names, "_R_filt.fastq"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names

#filtering and trimming, here truncation at 220 (Fwd) and 200 (Rev) bp, 
#2expected errors max (N discarded automatically)
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(220,200),
                     maxN=0, maxEE=2, truncQ=2, rm.phix=TRUE,
                     compress=TRUE, multithread=TRUE)

head(out) #to check how filtering and trimming worked

##continue here if skipped filter trim above
#check filtered files are in subdirectory created above
head(list.files(filtFs))

#learning error rates
errF <- learnErrors(filtFs, multithread = TRUE)
errR <- learnErrors(filtRs, multithread = TRUE)
#plotting errors
#plotErrors(errF, nominalQ=TRUE)
#plotErrors(errR, nominalQ=TRUE)
# the points should follow the black lines fairly well - ignore the red lines

#dereplicating reads
sam.names <- sapply(strsplit(basename(filtFs), "_"), `[`, 1)
derepFs <- derepFastq(filtFs)
names(derepFs) <- sam.names
derepRs <- derepFastq(filtRs)
names(derepRs) <- sam.names

##Infering Sequence Variants
dadaFs <- dada(derepFs, err = errF, pool = "pseudo", multithread = TRUE)
dadaFs[[1]]
dadaRs <- dada(derepRs, err = errR, pool = "pseudo", multithread = TRUE)
dadaRs[[1]]

##Merging paired ends
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs)
ROHR05 <- makeSequenceTable(mergers)
dim(ROHR05)
#[1]   117 8394
table(nchar(getSequences(ROHR05)))

#exporting files to use in the next part of the workflow
#pathoutput <- here("outputs/ROHR05/ROHR05.rds")
saveRDS(ROHR05, pathoutput)

ROHR05 = readRDS(here("outputs/ROHR05/ROHR05.rds"))
#identifying and removing chimeras
ROHR05.nochim <- removeBimeraDenovo(ROHR05, method="pooled", multithread=TRUE)
dim(ROHR05.nochim)
#[1]  117 7522 for ROHR01

##tracking changes through each step 
getN <- function(x) sum(getUniques(x))

# turn reads.in and reads.out in out dataframe into two separate vectors 
reads_in <- out[, "reads.in"]   # Extracts the first column
reads_out <- out[, "reads.out"] # Extracts the second column

# to avoid cutting out data of different lengths, need to add NAs to short columns 
max_length <- max(length(reads_in),
                  length(reads_out),
                  length(sapply(dadaFs, getN)), 
                  length(sapply(dadaRs, getN)), 
                  length(sapply(mergers, getN)), 
                  length(rowSums(ROHR05.nochim)))

pad_vector <- function(vec, max_length) {
  length(vec) <- max_length
  return(vec)
}

reads_in <- pad_vector(reads_in, max_length)
reads_out <- pad_vector(reads_out, max_length)
dadaFs_N <- pad_vector(sapply(dadaFs, getN), max_length)
dadaRs_N <- pad_vector(sapply(dadaRs, getN), max_length)
mergers_N <- pad_vector(sapply(mergers, getN), max_length)
nochim_N <- pad_vector(rowSums(ROHR05.nochim), max_length)
sam.names <- pad_vector(sam.names, max_length)

track <- cbind(reads_in, reads_out, dadaFs_N, dadaRs_N, mergers_N, nochim_N)
rownames(track) <- sam.names
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR",
                     "merged", "nonchim")

#save text file of tracking table
pathoutput_tracktable <- here("outputs/ROHR05/ROHR05_read_changes.txt")
write.table(track, pathoutput_tracktable, sep = "\t", quote = FALSE,
            col.names=NA)

# save rds of data with chimeras removed 
pathoutput_nochim_rds <- here("outputs/ROHR05/ROHR05.nochim.rds")
saveRDS(ROHR05.nochim, pathoutput_nochim_rds)
